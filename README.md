Fast Learning for Adaptive Source Separation in New Environments

The project focus on leveraging deep learning models for source separation, adapting to new environments in real time. This project will aim to improve separation performance in complex and dynamic soundscapes (take a noisy environments, such as overlapping human speakers with a background sound from other human at a distance in a reverb room) using deep learning models like convolutional neural networks (CNNs), recurrent neural networks (RNNs), or transformers.
